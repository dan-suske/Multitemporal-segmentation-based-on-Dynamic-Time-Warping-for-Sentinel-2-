{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "robust-compound",
   "metadata": {},
   "source": [
    "# Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import datetime \n",
    "import numpy as np\n",
    "import shapely\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import osgeo\n",
    "from osgeo import gdal, gdal_array, osr, ogr\n",
    "from tifffile import imwrite\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw, dtw\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import sobel\n",
    "from skimage.segmentation import slic, quickshift, watershed, felzenszwalb\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.metrics import (adapted_rand_error, variation_of_information)\n",
    "from skimage.measure import label\n",
    "from skimage.util import img_as_float\n",
    "from sentinelhub import MimeType, CRS, BBox, SentinelHubRequest, SentinelHubDownloadClient, \\\n",
    "    DataCollection, bbox_to_dimensions, DownloadRequest, SHConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting images\n",
    "def plot_image(image, factor=1.0, clip_range=None, **kwargs):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n",
    "    if clip_range is not None:\n",
    "        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n",
    "    else:\n",
    "        ax.imshow(image * factor, **kwargs)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your credentials here if you haven't already put them into config.json\n",
    "CLIENT_ID = ''\n",
    "CLIENT_SECRET = ''\n",
    "\n",
    "config = SHConfig()\n",
    "if CLIENT_ID and CLIENT_SECRET:\n",
    "    config.sh_client_id = CLIENT_ID\n",
    "    config.sh_client_secret = CLIENT_SECRET\n",
    "    \n",
    "if not config.sh_client_id or not config.sh_client_secret:\n",
    "    print(\"Warning! To use Process API, please provide the credentials (OAuth client ID and client secret).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-donna",
   "metadata": {},
   "source": [
    "# Choose the location based on WGS 84 coordinates "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-rochester",
   "metadata": {},
   "source": [
    "#### Easiest way to choose the location is http://bboxfinder.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_coords_wgs84 = [14.323528,50.094928,14.400433,50.139091]\n",
    "bbox = BBox(bbox=bbox_coords_wgs84, crs='EPSG:4326')\n",
    "resolution = 10\n",
    "bbox_size = bbox_to_dimensions(bbox, resolution=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-shelf",
   "metadata": {},
   "source": [
    "# RGB image generation used as a background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_true_color = \"\"\"\n",
    "    //VERSION=3\n",
    "\n",
    "    function setup() {\n",
    "        return {\n",
    "            input: [{\n",
    "                bands: [\"B02\", \"B03\", \"B04\"]\n",
    "            }],\n",
    "            output: {\n",
    "                bands: 3\n",
    "            }\n",
    "        };\n",
    "    }\n",
    "\n",
    "    function evaluatePixel(sample) {\n",
    "        return [3.5*sample.B04, 3.5*sample.B03, 3.5*sample.B02];\n",
    "    }\n",
    "\"\"\"\n",
    "request_true_color = SentinelHubRequest(\n",
    "    evalscript=evalscript_true_color,\n",
    "    input_data=[\n",
    "        SentinelHubRequest.input_data(\n",
    "            data_collection=DataCollection.SENTINEL2_L2A,\n",
    "            time_interval=('2020-04-01', '2020-12-31'),\n",
    "            mosaicking_order='leastCC'\n",
    "        )\n",
    "    ],\n",
    "    responses=[\n",
    "        SentinelHubRequest.output_response('default', MimeType.PNG)\n",
    "    ],\n",
    "    bbox=bbox,\n",
    "    size=bbox_size,\n",
    "    config=config\n",
    ")\n",
    "rgb_tiff = request_true_color.get_data()[0]\n",
    "plot_image(rgb_tiff/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-toyota",
   "metadata": {},
   "source": [
    "# Definition of the time for request of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime(2021,1,1)\n",
    "end = datetime.datetime(2021,11,30)\n",
    "n_chunks = 23 #Number of images requested, always add +1\n",
    "tdelta = (end - start) / n_chunks\n",
    "edges = [(start + i*tdelta).date().isoformat() for i in range(n_chunks)]\n",
    "slots = [(edges[i], edges[i+1]) for i in range(len(edges)-1)]\n",
    "\n",
    "print('Monthly time windows:\\n')\n",
    "for slot in slots:\n",
    "    print(slot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-shadow",
   "metadata": {},
   "source": [
    "# Evaluation script to request NDVI images along with cloud masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-protocol",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_ndvi = \"\"\"\n",
    "    //VERSION=3\n",
    "    function setup() {\n",
    "        return {\n",
    "            input: [{\n",
    "                bands: [\"B04\", \"B08\", \"CLM\"],\n",
    "                units: \"DN\"}],\n",
    "            output: {\n",
    "                bands: 2,\n",
    "                sampleType: SampleType.FLOAT32}};}\n",
    "    function evaluatePixel(sample) {\n",
    "      let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n",
    "      return [ ndvi, sample.CLM ]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndvi(time_interval):\n",
    "    return SentinelHubRequest(\n",
    "        evalscript=evalscript_ndvi,\n",
    "        input_data=[\n",
    "            SentinelHubRequest.input_data(\n",
    "                data_collection=DataCollection.SENTINEL2_L2A,\n",
    "                time_interval=time_interval,\n",
    "                mosaicking_order='leastCC'\n",
    "            )\n",
    "        ],\n",
    "        responses=[\n",
    "            SentinelHubRequest.output_response('default', MimeType.TIFF)\n",
    "        ],\n",
    "        bbox=bbox,\n",
    "        size=bbox_size,\n",
    "        config=config\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-accordance",
   "metadata": {},
   "source": [
    "# This might take a few seconds to minutes based on the area size and number of images requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of requests\n",
    "list_of_requests = [get_ndvi(slot) for slot in slots]\n",
    "list_of_requests = [request.download_list[0] for request in list_of_requests]\n",
    "\n",
    "# download data with multiple threads\n",
    "data_ndvi = SentinelHubDownloadClient(config=config).download(list_of_requests, max_threads=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-accessory",
   "metadata": {},
   "source": [
    "# Usage of the clouds mask to remove cloudy pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "while c < n_chunks-1:\n",
    "    [N,C]=np.dsplit(data_ndvi[c],data_ndvi[c].shape[-1])\n",
    "    data_ndvi[c]=(1-C)*N\n",
    "    data_ndvi[c] = np.array(data_ndvi[c])\n",
    "    data_ndvi[c][data_ndvi[c] == 0] = 'nan'\n",
    "    c=c+1\n",
    "stack=np.dstack((data_ndvi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-raleigh",
   "metadata": {},
   "source": [
    "# Time to plot the images without cloud pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-ukraine",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ncols = 4\n",
    "nrows = 9 #This number is to be set based on the number of the images\n",
    "aspect_ratio = bbox_size[0] / bbox_size[1]\n",
    "subplot_kw = {'xticks': [], 'yticks': [], 'frame_on': False}\n",
    "\n",
    "fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(5 * ncols * aspect_ratio, 5 * nrows),\n",
    "                        subplot_kw=subplot_kw)\n",
    "\n",
    "for idx, image in enumerate(data_ndvi):\n",
    "    ax = axs[idx // ncols][idx % ncols]\n",
    "    ax.imshow(np.clip(image * 1, 2.5/255, 1))\n",
    "    ax.set_title(f'{slots[idx][0]}  -  {slots[idx][1]}', fontsize=10)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-lodge",
   "metadata": {},
   "source": [
    "# This function removes the images based on the maximum cloudness being set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-glenn",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_cloudiness = 20\n",
    "\n",
    "numrows = len(stack)\n",
    "numcols = len(stack[0])\n",
    "x=0\n",
    "stay = []\n",
    "xslots=[]\n",
    "\n",
    "for x in range(0,n_chunks-1):\n",
    "    cloudiness = np.isnan(data_ndvi[x]).sum()*100/(numcols * numrows)\n",
    "    if cloudiness < max_cloudiness:\n",
    "        stay.append(x)\n",
    "        xslots.append(slots[x])\n",
    "    else:\n",
    "        print(f'The image from {slots[x]} contains {cloudiness}% of clouds and is therefore removed')\n",
    "\n",
    "x=2\n",
    "stacknew = np.dstack((data_ndvi[stay[0]],data_ndvi[stay[1]]))\n",
    "while x<=len(stay)-1:\n",
    "    stacknew = np.dstack((stacknew,data_ndvi[stay[x]]))\n",
    "    x=x+1\n",
    "stack = np.swapaxes(stacknew,0,2)\n",
    "stack = np.swapaxes(stack,1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-lawsuit",
   "metadata": {},
   "source": [
    "# Visualization after removal of too cloudy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-growing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ncols = 4\n",
    "nrows = int((len(stack)/ ncols)+1)\n",
    "aspect_ratio = bbox_size[0] / bbox_size[1]\n",
    "subplot_kw = {'xticks': [], 'yticks': [], 'frame_on': False}\n",
    "\n",
    "fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(5 * ncols * aspect_ratio, 5 * nrows),\n",
    "                        subplot_kw=subplot_kw)\n",
    "\n",
    "for idx, image in enumerate(stack):\n",
    "    ax = axs[idx // ncols][idx % ncols]\n",
    "    ax.imshow(np.clip(image * 1, 2.5/255, 1))\n",
    "    ax.set_title(f'{xslots[idx][0]}  -  {xslots[idx][1]}', fontsize=10)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-relationship",
   "metadata": {},
   "source": [
    "# Interpolation and extrapolation of the pixels with 'nan' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=0\n",
    "y=0\n",
    "numrows = len(stack[0,:])\n",
    "numcols = len(stack[0,0,:])\n",
    "\n",
    "for x in range(0, numrows-1):\n",
    "    for y in range(0, numcols-1):\n",
    "        if np.isnan(stack[:,x,y]).any():\n",
    "            stack[:,x,y]=pd.Series(stack[:,x,y]).interpolate(method = 'polynomial', order = 2,limit_area = None)\n",
    "            stack[:,x,y]=pd.Series(stack[:,x,y]).interpolate(limit_area = None, limit_direction = 'forward')# extrapolation\n",
    "            stack[:,x,y]=pd.Series(stack[:,x,y]).interpolate(limit_area = None, limit_direction = 'backward')# extrapolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-batman",
   "metadata": {},
   "source": [
    "# Plotting the images after interpolation & extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-cemetery",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ncols = 4\n",
    "nrows = int(((len(stack)+1)/ ncols)+1)\n",
    "aspect_ratio = bbox_size[0] / bbox_size[1]\n",
    "subplot_kw = {'xticks': [], 'yticks': [], 'frame_on': False}\n",
    "\n",
    "fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(5 * ncols * aspect_ratio, 5 * nrows),\n",
    "                        subplot_kw=subplot_kw)\n",
    "\n",
    "for idx, image in enumerate(stack):\n",
    "    ax = axs[idx // ncols][idx % ncols]\n",
    "    ax.imshow(np.clip(image * 1, 2.5/255, 1))\n",
    "    ax.set_title(f'{xslots[idx][0]}  -  {xslots[idx][1]}', fontsize=10)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-silly",
   "metadata": {},
   "source": [
    "# Putting the images into the multichannel image/ 3D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "stackx = np.swapaxes(stack,0,2)\n",
    "stackx = np.swapaxes(stackx,0,1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-runner",
   "metadata": {},
   "source": [
    "# Creation of stacked image from 3 images to run other segmentation examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y and z represent the images to be used in other segmentations\n",
    "x = int(len(stackx[1,1,:])/4)\n",
    "y = int(len(stackx[1,1,:])/2)\n",
    "z = int(len(stackx[1,1,:])/(4)*3)\n",
    "imgq = np.dstack((stackx[:,:,x],stackx[:,:,y],stackx[:,:,z]))\n",
    "imgq = np.nan_to_num(imgq, copy=True, nan=0.0, posinf=None, neginf=None)\n",
    "imgq = imgq.astype('double')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-sampling",
   "metadata": {},
   "source": [
    "# Segmentation based on one image, mainly for comparison and validation purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-ocean",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_segmentation (input_stack, max_distance, minimum_area):\n",
    "\n",
    "    begin_time = datetime.datetime.now()\n",
    "    input_stack=np.nan_to_num(input_stack, copy=True, nan=0.0, posinf=None, neginf=None)\n",
    "    numrows = len(input_stack)\n",
    "    numcols = len(input_stack[0])\n",
    "    seg_output = np.ones((numrows, numcols))\n",
    "    input_raster = np.zeros((numrows, numcols))\n",
    "    x=0\n",
    "    y=0\n",
    "    n=1\n",
    "\n",
    "    for x in range(0, numrows-1):\n",
    "        for y in range(0, numcols-1):\n",
    "            # raster s hodnotami NDVI\n",
    "            current = input_stack[x,y]\n",
    "            left = input_stack[x,y-1]\n",
    "            upright = input_stack[x-1,y+1]\n",
    "            right = input_stack[x,y+1] \n",
    "            rightbot = input_stack[x+1,y+1] \n",
    "            bot = input_stack[x+1,y] \n",
    "            leftbot = input_stack[x+1,y-1] \n",
    "\n",
    "            rupright  = abs(current - upright)\n",
    "            rright  = abs(current - right)\n",
    "            rrightbot = abs(current - rightbot)\n",
    "            rbot = abs(current - bot)\n",
    "            rleftbot = abs(current - leftbot)\n",
    "\n",
    "            listn = [rupright, rright, rrightbot, rbot, rleftbot]\n",
    "            maxcorr = max(listn)\n",
    "            if maxcorr < max_distance: \n",
    "                \n",
    "                op_current = seg_output[x,y]\n",
    "                op_upright = seg_output[x-1,y+1]\n",
    "                op_right = seg_output[x,y+1] \n",
    "                op_rightbot = seg_output[x+1,y+1] \n",
    "                op_bot = seg_output[x+1,y] \n",
    "                op_leftbot = seg_output[x+1,y-1]\n",
    "\n",
    "                r_current = input_raster[x,y]\n",
    "                r_upright = input_raster[x-1,y+1]\n",
    "                r_right = input_raster[x,y+1] \n",
    "                r_rightbot = input_raster[x+1,y+1] \n",
    "                r_bot = input_raster[x+1,y] \n",
    "                r_leftbot = input_raster[x+1,y-1] \n",
    "\n",
    "                if seg_output[x,y] == 1:\n",
    "                    n=n+1\n",
    "                    seg_output[x,y] = n\n",
    "\n",
    "\n",
    "                if rright < max_distance:\n",
    "                    input_raster[x,y+1] = rright\n",
    "                    if seg_output[x,y+1] != 1: \n",
    "                        np.place(seg_output, seg_output == seg_output[x,y+1], seg_output[x,y])\n",
    "                        input_raster[x,y+1] = rright\n",
    "                    else: \n",
    "                        seg_output[x,y+1] = seg_output[x,y]\n",
    "                        input_raster[x,y+1] = rright\n",
    "\n",
    "                if rrightbot < max_distance:\n",
    "                    input_raster[x+1,y+1] = rrightbot\n",
    "                    seg_output[x+1,y+1] = seg_output[x,y]\n",
    "\n",
    "                if rbot < max_distance:\n",
    "                    if (input_raster[x+1,y] != 0):\n",
    "                        if (rbot > input_raster[x+1,y]):\n",
    "                            input_raster[x+1,y] = rbot\n",
    "                            seg_output[x+1,y] = seg_output[x,y]\n",
    "                    else:\n",
    "                        input_raster[x+1,y] = rbot\n",
    "                        seg_output[x+1,y] = seg_output[x,y]      \n",
    "\n",
    "                if rleftbot < max_distance:\n",
    "                    if (input_raster[x+1,y-1] != 0):\n",
    "                        if (rleftbot > input_raster[x+1,y-1] ):\n",
    "                            input_raster[x+1,y-1] = rleftbot\n",
    "                            seg_output[x+1,y-1] = seg_output[x,y]\n",
    "                    else:\n",
    "                        input_raster[x+1,y-1] = rleftbot\n",
    "                        seg_output[x+1,y-1] = seg_output[x,y]    \n",
    "\n",
    "                if rupright < max_distance:\n",
    "                    if seg_output[x-1,y+1] != 1:\n",
    "                        np.place(seg_output, seg_output == seg_output[x-1,y+1], seg_output[x,y])\n",
    "                        input_raster[x-1,y+1] = rupright\n",
    "\n",
    "    img = seg_output\n",
    "    img[np.sum(img==img[:,None],axis=1)<minimum_area] = 1\n",
    "    img[np.where(img <2)] = 0\n",
    "    img[np.where(img >1)] = 1\n",
    "    print(datetime.datetime.now() - begin_time)\n",
    "    plot_image(mark_boundaries(rgb_tiff/255, seg_output.astype('int')))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-nowhere",
   "metadata": {},
   "source": [
    "### Example of how to run segmentation based on one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-patrick",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "one_image_example = image_segmentation(stackx[:,:,5], 0.15,  5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-mauritius",
   "metadata": {},
   "source": [
    "# Definition of the segmentation function based on Euclidean Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-homework",
   "metadata": {},
   "source": [
    "### Much faster then DTW, but also less accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_segmentation (input_stack, ed, minimum_area):\n",
    "\n",
    "    begin_time = datetime.datetime.now()\n",
    "    input_stack=np.nan_to_num(input_stack, copy=True, nan=0.0, posinf=None, neginf=None)\n",
    "    numrows = len(input_stack)\n",
    "    numcols = len(input_stack[0])\n",
    "    seg_output = np.ones((numrows, numcols))\n",
    "    input_raster = np.zeros((numrows, numcols))\n",
    "    x=0\n",
    "    y=0\n",
    "    n=1\n",
    "\n",
    "    for x in range(0, numrows-1):\n",
    "        for y in range(0, numcols-1):\n",
    "            current = input_stack[x,y,:]\n",
    "            left = input_stack[x,y-1,:]\n",
    "            upright = input_stack[x-1,y+1,:]\n",
    "            right = input_stack[x,y+1,:] \n",
    "            rightbot = input_stack[x+1,y+1,:] \n",
    "            bot = input_stack[x+1,y,:] \n",
    "            leftbot = input_stack[x+1,y-1,:] \n",
    "\n",
    "            rupright  = sum(abs(current - upright))\n",
    "            rright  = sum(abs(current - right))\n",
    "            rrightbot = sum(abs(current - rightbot))\n",
    "            rbot = sum(abs(current - bot))\n",
    "            rleftbot = sum(abs(current - leftbot))\n",
    "\n",
    "            listn = [rupright, rright, rrightbot, rbot, rleftbot]\n",
    "            maxcorr = max(listn)\n",
    "            if maxcorr < ed: \n",
    "\n",
    "                op_current = seg_output[x,y]\n",
    "                op_upright = seg_output[x-1,y+1]\n",
    "                op_right = seg_output[x,y+1] \n",
    "                op_rightbot = seg_output[x+1,y+1] \n",
    "                op_bot = seg_output[x+1,y] \n",
    "                op_leftbot = seg_output[x+1,y-1]\n",
    "\n",
    "                r_current = input_raster[x,y]\n",
    "                r_upright = input_raster[x-1,y+1]\n",
    "                r_right = input_raster[x,y+1] \n",
    "                r_rightbot = input_raster[x+1,y+1] \n",
    "                r_bot = input_raster[x+1,y] \n",
    "                r_leftbot = input_raster[x+1,y-1] \n",
    "\n",
    "                if seg_output[x,y] == 1:\n",
    "                    n=n+1\n",
    "                    seg_output[x,y] = n\n",
    "\n",
    "                if rright < ed:\n",
    "                    input_raster[x,y+1] = rright\n",
    "                    if seg_output[x,y+1] != 1: \n",
    "                        np.place(seg_output, seg_output == seg_output[x,y+1], seg_output[x,y])\n",
    "                        input_raster[x,y+1] = rright\n",
    "                    else: \n",
    "                        seg_output[x,y+1] = seg_output[x,y]\n",
    "                        input_raster[x,y+1] = rright\n",
    "\n",
    "                if rrightbot < ed:\n",
    "                    input_raster[x+1,y+1] = rrightbot\n",
    "                    seg_output[x+1,y+1] = seg_output[x,y]\n",
    "\n",
    "                if rbot < ed:\n",
    "                    if (input_raster[x+1,y] != 0):\n",
    "                        if (rbot > input_raster[x+1,y]):\n",
    "                            input_raster[x+1,y] = rbot\n",
    "                            seg_output[x+1,y] = seg_output[x,y]\n",
    "                    else:\n",
    "                        input_raster[x+1,y] = rbot\n",
    "                        seg_output[x+1,y] = seg_output[x,y]         \n",
    "\n",
    "                if rleftbot < ed:\n",
    "                    if (input_raster[x+1,y-1] != 0):\n",
    "                        if (rleftbot > input_raster[x+1,y-1] ):\n",
    "                            input_raster[x+1,y-1] = rleftbot\n",
    "                            seg_output[x+1,y-1] = seg_output[x,y]\n",
    "                    else:\n",
    "                        input_raster[x+1,y-1] = rleftbot\n",
    "                        seg_output[x+1,y-1] = seg_output[x,y]         \n",
    "\n",
    "                if rupright < ed:\n",
    "                    if seg_output[x-1,y+1] != 1:\n",
    "                        np.place(seg_output, seg_output == seg_output[x-1,y+1], seg_output[x,y])\n",
    "                        input_raster[x-1,y+1] = rupright\n",
    "\n",
    "    img = seg_output\n",
    "    img[np.sum(img==img[:,None],axis=1)<minimum_area] = 1\n",
    "    img[np.where(img <2)] = 0\n",
    "    img[np.where(img >1)] = 1\n",
    "    print(datetime.datetime.now() - begin_time)\n",
    "    plot_image(mark_boundaries(rgb_tiff/255, seg_output.astype('int')))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-calendar",
   "metadata": {},
   "source": [
    "## Example of function to run, input stack is set, along with maximum distance for segmentation, last attribute is minimal size of one segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-billion",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ed_segmentation_example = euclidean_segmentation(stackx, 0.35,  5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-mistake",
   "metadata": {},
   "source": [
    "# Segmentation based on DTW using any number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-presentation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def DTW_segmentation (input_stack, dtw, minimum_area):\n",
    "\n",
    "    begin_time = datetime.datetime.now()\n",
    "    input_stack=np.nan_to_num(input_stack, copy=True, nan=0.0, posinf=None, neginf=None)\n",
    "    numrows = len(input_stack)\n",
    "    numcols = len(input_stack[0])\n",
    "    seg_output = np.ones((numrows, numcols))\n",
    "    input_raster = np.zeros((numrows, numcols))\n",
    "    x=0\n",
    "    y=0\n",
    "    n=1\n",
    "\n",
    "    for x in range(0, numrows-1):\n",
    "        for y in range(0, numcols-1):\n",
    "            current = input_stack[x,y,:]\n",
    "            left = input_stack[x,y-1,:]\n",
    "            upright = input_stack[x-1,y+1,:]\n",
    "            right = input_stack[x,y+1,:] \n",
    "            rightbot = input_stack[x+1,y+1,:] \n",
    "            bot = input_stack[x+1,y,:] \n",
    "            leftbot = input_stack[x+1,y-1,:] \n",
    "\n",
    "            rupright, path  = fastdtw(current, upright)\n",
    "            rright, path  = fastdtw(current, right)\n",
    "            rrightbot, path  = fastdtw(current, rightbot)\n",
    "            rbot, path  = fastdtw(current, bot)\n",
    "            rleftbot, path  = fastdtw(current, leftbot)\n",
    "\n",
    "            listn = [rupright, rright, rrightbot, rbot, rleftbot]\n",
    "            maxcorr = max(listn)\n",
    "            if maxcorr < dtw: \n",
    "\n",
    "                op_current = seg_output[x,y]\n",
    "                op_upright = seg_output[x-1,y+1]\n",
    "                op_right = seg_output[x,y+1] \n",
    "                op_rightbot = seg_output[x+1,y+1] \n",
    "                op_bot = seg_output[x+1,y] \n",
    "                op_leftbot = seg_output[x+1,y-1]\n",
    "\n",
    "                r_current = input_raster[x,y]\n",
    "                r_upright = input_raster[x-1,y+1]\n",
    "                r_right = input_raster[x,y+1] \n",
    "                r_rightbot = input_raster[x+1,y+1] \n",
    "                r_bot = input_raster[x+1,y] \n",
    "                r_leftbot = input_raster[x+1,y-1] \n",
    "\n",
    "                if seg_output[x,y] == 1:\n",
    "                    n=n+1\n",
    "                    seg_output[x,y] = n\n",
    "\n",
    "                if rright < dtw:\n",
    "                    input_raster[x,y+1] = rright\n",
    "                    if seg_output[x,y+1] != 1: \n",
    "                        np.place(seg_output, seg_output == seg_output[x,y+1], seg_output[x,y])\n",
    "                        input_raster[x,y+1] = rright\n",
    "                    else: \n",
    "                        seg_output[x,y+1] = seg_output[x,y]\n",
    "                        input_raster[x,y+1] = rright\n",
    "\n",
    "                if rrightbot < dtw:\n",
    "                    input_raster[x+1,y+1] = rrightbot\n",
    "                    seg_output[x+1,y+1] = seg_output[x,y]\n",
    "\n",
    "                if rbot < dtw:\n",
    "                    if (input_raster[x+1,y] != 0):\n",
    "                        if (rbot > input_raster[x+1,y]):\n",
    "                            input_raster[x+1,y] = rbot\n",
    "                            seg_output[x+1,y] = seg_output[x,y]\n",
    "                    else:\n",
    "                        input_raster[x+1,y] = rbot\n",
    "                        seg_output[x+1,y] = seg_output[x,y]\n",
    "\n",
    "                if rleftbot < dtw:\n",
    "                    if (input_raster[x+1,y-1] != 0):\n",
    "                        if (rleftbot > input_raster[x+1,y-1] ):\n",
    "                            input_raster[x+1,y-1] = rleftbot\n",
    "                            seg_output[x+1,y-1] = seg_output[x,y]\n",
    "                    else:\n",
    "                        input_raster[x+1,y-1] = rleftbot\n",
    "                        seg_output[x+1,y-1] = seg_output[x,y]\n",
    "\n",
    "                if rupright < dtw:\n",
    "                    if seg_output[x-1,y+1] != 1:\n",
    "                        np.place(seg_output, seg_output == seg_output[x-1,y+1], seg_output[x,y])\n",
    "                        input_raster[x-1,y+1] = rupright\n",
    "\n",
    "    img = seg_output\n",
    "    img[np.sum(img==img[:,None],axis=1)<minimum_area] = 1\n",
    "    img[np.where(img <2)] = 0\n",
    "    img[np.where(img >1)] = 1\n",
    "    print(datetime.datetime.now() - begin_time)\n",
    "    plot_image(mark_boundaries(rgb_tiff/255, seg_output.astype('int')))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-coordination",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DTW_segmentation_example = DTW_segmentation(stackx, 0.4,  5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-binary",
   "metadata": {},
   "source": [
    "# Quickshift Segmentation (based on three images maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imgq.astype('double')\n",
    "segments_quick = quickshift(imgq, kernel_size=4, max_dist=30, ratio=0.8, sigma=1)\n",
    "plot_image(mark_boundaries(rgb_tiff/255, segments_quick))\n",
    "print(f'Quickshift number of segments: {len(np.unique(segments_quick))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-calibration",
   "metadata": {},
   "source": [
    "# Watershed segmentation (based on three images maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = stackx[:,:,5].astype('double')\n",
    "gradient = sobel(rgb2gray(img))\n",
    "segments_watershed = watershed(gradient, markers=400, compactness=0.000006)\n",
    "plot_image(mark_boundaries(rgb_tiff/255, segments_watershed))\n",
    "print(f'Quickshift number of segments: {len(np.unique(segments_watershed))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-solid",
   "metadata": {},
   "source": [
    "# SLIC segmentation (based on three images maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rgb_tiff.astype('float')\n",
    "segments_slic = slic(img, n_segments=500, compactness=1000)\n",
    "plot_image(mark_boundaries(rgb_tiff/255, segments_slic))\n",
    "print(f'Quickshift number of segments: {len(np.unique(segments_slic))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-twins",
   "metadata": {},
   "source": [
    "# Felzenszwalb segmentation, works on multiple images as well, fastest, well working method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = stackx.astype('double')\n",
    "segments_fz = felzenszwalb(img, scale=1500, sigma=0, min_size=5)\n",
    "plot_image(mark_boundaries(rgb_tiff/255, segments_fz))\n",
    "print(f'Felzenszwalb number of segments: {len(np.unique(segments_fz))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-backup",
   "metadata": {},
   "source": [
    "# Import of ground truth data, needs to be in format of binary raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = gdal.Open(\"final_raster.tif\")\n",
    "im_true = np.array(ds.GetRasterBand(1).ReadAsArray()).astype('int')\n",
    "plot_image(mark_boundaries(rgb_tiff/255, im_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-spotlight",
   "metadata": {},
   "source": [
    "# Validation of set segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-shopping",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image = rgb_tiff\n",
    "\n",
    "init_ls = np.zeros(image.shape, dtype=np.int8)\n",
    "init_ls[10:-10, 10:-10] = 1\n",
    "im_test1=DTW_segmentation_example.astype('int')\n",
    "im_test2=ed_segmentation_example.astype('int')\n",
    "im_test3=one_image_example.astype('int')\n",
    "\n",
    "\n",
    "method_names = ['DTW segmentation', 'Euclidean Distance segmentation','Segmentation based on one image']\n",
    "\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "split_list = []\n",
    "merge_list = []\n",
    "for name, im_test in zip(method_names, [im_test1, im_test2, im_test3]):\n",
    "    error, precision, recall = adapted_rand_error(im_true, im_test)\n",
    "    splits, merges = variation_of_information(im_true, im_test)\n",
    "    split_list.append(splits)\n",
    "    merge_list.append(merges)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    print(f\"\\n## Method: {name}\")\n",
    "    print(f\"Adapted Rand error: {error}\")\n",
    "    print(f\"Adapted Rand precision: {precision}\")\n",
    "    print(f\"Adapted Rand recall: {recall}\")\n",
    "    print(f\"False Splits: {splits}\")\n",
    "    print(f\"False Merges: {merges}\")\n",
    "    \n",
    "short_method_names = ['DTW', 'ED', '1Im']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(9, 6), constrained_layout=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].scatter(merge_list, split_list)\n",
    "for i, txt in enumerate(short_method_names):\n",
    "    ax[0].annotate(txt, (merge_list[i], split_list[i]),\n",
    "                   verticalalignment='center')\n",
    "ax[0].set_xlabel('False Merges (bits)')\n",
    "ax[0].set_ylabel('False Splits (bits)')\n",
    "ax[0].set_title('Split Variation of Information')\n",
    "\n",
    "ax[1].scatter(precision_list, recall_list)\n",
    "for i, txt in enumerate(short_method_names):\n",
    "    ax[1].annotate(txt, (precision_list[i], recall_list[i]),\n",
    "                   verticalalignment='center')\n",
    "ax[1].set_xlabel('Precision')\n",
    "ax[1].set_ylabel('Recall')\n",
    "ax[1].set_title('Adapted Rand precision vs. recall')\n",
    "ax[1].set_xlim(0, 1)\n",
    "ax[1].set_ylim(0, 1)\n",
    "\n",
    "ax[2].imshow(mark_boundaries(image, im_true))\n",
    "ax[2].set_title('True Segmentation')\n",
    "ax[2].set_axis_off()\n",
    "\n",
    "ax[3].imshow(mark_boundaries(image, im_test1))\n",
    "ax[3].set_title('DTW Segmentation')\n",
    "ax[3].set_axis_off()\n",
    "\n",
    "ax[4].imshow(mark_boundaries(image, im_test2))\n",
    "ax[4].set_title('Euclidean Distance Segmentation')\n",
    "ax[4].set_axis_off()\n",
    "\n",
    "ax[5].imshow(mark_boundaries(image, im_test3))\n",
    "ax[5].set_title('One Image Segmentation')\n",
    "ax[5].set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-publicity",
   "metadata": {},
   "source": [
    "# Export of the chosen segmentation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_output (input, output_name): \n",
    "    xmin,ymin,xmax,ymax = bbox_coords_wgs84\n",
    "    nrows,ncols = np.shape(input)\n",
    "    xres = (xmax-xmin)/float(ncols)\n",
    "    yres = (ymax-ymin)/float(nrows)\n",
    "    geotransform=(xmin,xres,0,ymax,0, -yres)   \n",
    "\n",
    "    output_raster = gdal.GetDriverByName('GTiff').Create((output_name),ncols, nrows, 1 ,gdal.GDT_Float32)  \n",
    "    output_raster.SetGeoTransform(geotransform)  \n",
    "    srs = osr.SpatialReference()                 \n",
    "    srs.ImportFromEPSG(4326)                     \n",
    "    output_raster.SetProjection( srs.ExportToWkt() )   \n",
    "    output_raster.GetRasterBand(1).WriteArray(input)  \n",
    "    output_raster.FlushCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-arlington",
   "metadata": {},
   "source": [
    "# Example how to run the export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_output (DTW_segmentation_example, 'dtw_segmentation_example.tif')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
